{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q5RCysOH9jUp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rVRV4pYw9jUt"
   },
   "source": [
    "It is highly recommended to read the documentation before implementing any alogorithm.\n",
    "\n",
    "LINEAR REGRESSION : \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html <br>\n",
    "LOGISTIC REGRESSION :\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html<br>\n",
    "SVM REGRESSOR :\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html<br>\n",
    "SVM CLASSIFIER :\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html<br>\n",
    "DECISION TREE CLASSIFIER :\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html<br>\n",
    "DECISION TREE Regressor :\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html<br>\n",
    "RANDOM FOREST CLASSIFIER :\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html<br>\n",
    "RANDOM FOREST CLASSIFIER :\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html<br>\n",
    "\n",
    "METRICS:\n",
    "R2_SCORE : http://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html<br>\n",
    "MSE : http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html<br>\n",
    "MAE : http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html<br>\n",
    "Confusion Matrix : https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_lclLEtp9jUu"
   },
   "source": [
    "WRITE THE CODE FOR IMPORTING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRV20Tv-9jUu"
   },
   "outputs": [],
   "source": [
    "#WRITE CODE HERE IMPORT THE DATA AS 'data'\n",
    "data_train=pd.read_csv(r'F:\\NITIE\\Self Learnings\\Summer Analytics Course\\Assignments\\Week 6\\train.csv')\n",
    "data_test=pd.read_csv(r'F:\\NITIE\\Self Learnings\\Summer Analytics Course\\Assignments\\Week 6\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fmude2rPzgyy"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>...</th>\n",
       "      <th>PerformanceRating</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <th>CommunicationSkill</th>\n",
       "      <th>Behaviour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-Travel</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>571</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1614</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Sales</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>842</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Other</td>\n",
       "      <td>689</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Age  Attrition BusinessTravel              Department  \\\n",
       "0   1   30          0     Non-Travel  Research & Development   \n",
       "1   2   36          0  Travel_Rarely  Research & Development   \n",
       "2   3   55          1  Travel_Rarely                   Sales   \n",
       "3   4   39          0  Travel_Rarely  Research & Development   \n",
       "4   5   37          0  Travel_Rarely  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeNumber  \\\n",
       "0                 2          3        Medical             571   \n",
       "1                12          4  Life Sciences            1614   \n",
       "2                 2          1        Medical             842   \n",
       "3                24          1  Life Sciences            2014   \n",
       "4                 3          3          Other             689   \n",
       "\n",
       "   EnvironmentSatisfaction  ... PerformanceRating  StockOptionLevel  \\\n",
       "0                        3  ...                 3                 0   \n",
       "1                        3  ...                 3                 2   \n",
       "2                        3  ...                 3                 0   \n",
       "3                        1  ...                 3                 0   \n",
       "4                        3  ...                 3                 1   \n",
       "\n",
       "  TotalWorkingYears  TrainingTimesLastYear YearsAtCompany  YearsInCurrentRole  \\\n",
       "0                12                      2             11                   7   \n",
       "1                 7                      2              3                   2   \n",
       "2                12                      3              9                   7   \n",
       "3                18                      2              7                   7   \n",
       "4                10                      2             10                   7   \n",
       "\n",
       "   YearsSinceLastPromotion YearsWithCurrManager  CommunicationSkill  Behaviour  \n",
       "0                        6                    7                   4          1  \n",
       "1                        1                    1                   2          1  \n",
       "2                        7                    3                   5          1  \n",
       "3                        1                    7                   4          1  \n",
       "4                        7                    8                   1          1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Age</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>...</th>\n",
       "      <th>PerformanceRating</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <th>CommunicationSkill</th>\n",
       "      <th>Behaviour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>377</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Sales</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Medical</td>\n",
       "      <td>653</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>474</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>827</td>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>Non-Travel</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>972</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Age BusinessTravel              Department  DistanceFromHome  \\\n",
       "0   1   28  Travel_Rarely  Research & Development                 9   \n",
       "1   2   31  Travel_Rarely                   Sales                 6   \n",
       "2   3   37  Travel_Rarely  Research & Development                 6   \n",
       "3   4   42  Travel_Rarely  Research & Development                 1   \n",
       "4   5   45     Non-Travel  Research & Development                 4   \n",
       "\n",
       "   Education EducationField  EmployeeNumber  EnvironmentSatisfaction  Gender  \\\n",
       "0          3        Medical             377                        4    Male   \n",
       "1          4        Medical             653                        1    Male   \n",
       "2          3        Medical             474                        3    Male   \n",
       "3          2  Life Sciences             827                        4  Female   \n",
       "4          2  Life Sciences             972                        3    Male   \n",
       "\n",
       "   ...  PerformanceRating StockOptionLevel  TotalWorkingYears  \\\n",
       "0  ...                  4                1                  5   \n",
       "1  ...                  4                2                 13   \n",
       "2  ...                  3                2                 13   \n",
       "3  ...                  3                1                  8   \n",
       "4  ...                  3                0                  9   \n",
       "\n",
       "  TrainingTimesLastYear  YearsAtCompany  YearsInCurrentRole  \\\n",
       "0                     3               5                   2   \n",
       "1                     4               7                   7   \n",
       "2                     2               7                   7   \n",
       "3                     4               4                   3   \n",
       "4                     5               9                   7   \n",
       "\n",
       "  YearsSinceLastPromotion  YearsWithCurrManager  CommunicationSkill  Behaviour  \n",
       "0                       0                     4                   5          1  \n",
       "1                       5                     7                   3          1  \n",
       "2                       6                     7                   4          1  \n",
       "3                       0                     2                   5          1  \n",
       "4                       0                     8                   2          1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFgdtQPl9jUx"
   },
   "source": [
    "ONE HOT ENCODING THE COLOR COLUMN AND THEN DROPPING THE COLOR COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wr-anAzs9jUy"
   },
   "outputs": [],
   "source": [
    "#ONE HOT ENCODING THE COLOR COLUMN\n",
    "#data = pd.concat([data,pd.get_dummies(data['color']).drop('white',axis=1)],axis = 1)\n",
    "#data = data.drop('color',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dAxfI_kg9jU0"
   },
   "outputs": [],
   "source": [
    "# VIEWING THE DATA ONCE\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ZcVR3RC9jU4"
   },
   "source": [
    "WE USE THE train_test_split_function TO SPLIT THE DATA INTO TRAIN AND TEST <br>\n",
    "HERE WE IMPORT IT FROM SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "di5Jh08_9jU4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ll5Q2xCm9jU7"
   },
   "source": [
    "LET US LOOK AT THE PRICES DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZu32pba9jU7"
   },
   "outputs": [],
   "source": [
    "#plt.hist(data_train['Attrition']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jn6ZMkZd9jU_"
   },
   "source": [
    "IT IS LEFT-SKEWED, WE HAVE LEARNT HOW TO HANDLE SKEWED DATA<br>\n",
    "We will either use log transform or sqrt transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nC13GB_f9jU_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"plt.hist(np.sqrt(data['price']));\\nplt.title('SQRT TRANSFORM');\\nplt.show()\\nplt.hist(np.log(data['price']));\\nplt.title('LOG TRANSFORM');\\nplt.show()\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WE HAVE WRITTEN THE CODE FOR PLOTTING THE HISTOGRAM FOR THE LOG-TRANSFORMED PRICE COLUMN AND SQRT TRANSFORMED SQRT COLUMN.\n",
    "\"\"\"plt.hist(np.sqrt(data['price']));\n",
    "plt.title('SQRT TRANSFORM');\n",
    "plt.show()\n",
    "plt.hist(np.log(data['price']));\n",
    "plt.title('LOG TRANSFORM');\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CIxuDmN89jVC"
   },
   "source": [
    "CLEARLY SQRT TRANSFORM IS BETTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZEDTdMPP9jVC"
   },
   "outputs": [],
   "source": [
    "#WE CONVERT PRICES TO THEIR SQRT AND ROUND OFF DECIMALS TO TWO\n",
    "#data['price'] = round(np.sqrt(data['price']),2)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DsRrd_c79jVG"
   },
   "outputs": [],
   "source": [
    "# HERE WE SPLIT DATA INTO TRAIN TEST SPLIT\n",
    "#X_train,X_test,y_train,y_test = tts(data.drop('price',axis = 1),data['price'],test_size = 0.2,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=data_train.drop(['DistanceFromHome','Attrition','Behaviour'],axis=1)\n",
    "X_test=data_test.drop(['DistanceFromHome','Behaviour'],axis=1)\n",
    "y_train=data_train.Attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                            int64\n",
       "Age                           int64\n",
       "BusinessTravel             category\n",
       "Department                 category\n",
       "Education                     int64\n",
       "EducationField             category\n",
       "EmployeeNumber                int64\n",
       "EnvironmentSatisfaction       int64\n",
       "Gender                     category\n",
       "JobInvolvement                int64\n",
       "JobRole                    category\n",
       "JobSatisfaction               int64\n",
       "MaritalStatus              category\n",
       "MonthlyIncome                 int64\n",
       "NumCompaniesWorked            int64\n",
       "OverTime                   category\n",
       "PercentSalaryHike             int64\n",
       "PerformanceRating             int64\n",
       "StockOptionLevel              int64\n",
       "TotalWorkingYears             int64\n",
       "TrainingTimesLastYear         int64\n",
       "YearsAtCompany                int64\n",
       "YearsInCurrentRole            int64\n",
       "YearsSinceLastPromotion       int64\n",
       "YearsWithCurrManager          int64\n",
       "CommunicationSkill            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[X_train.select_dtypes(['object']).columns] = X_train.select_dtypes(['object']).apply(lambda x: x.astype('category'))\n",
    "X_test[X_test.select_dtypes(['object']).columns] = X_test.select_dtypes(['object']).apply(lambda x: x.astype('category'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[X_train.select_dtypes(['category']).columns]\n",
    "X_train[\"BusinessTravel\"] = X_train[\"BusinessTravel\"].cat.codes\n",
    "X_train[\"Department\"] = X_train[\"Department\"].cat.codes\n",
    "X_train[\"EducationField\"] = X_train[\"EducationField\"].cat.codes\n",
    "X_train[\"Gender\"] = X_train[\"Gender\"].cat.codes\n",
    "X_train[\"JobRole\"] = X_train[\"JobRole\"].cat.codes\n",
    "X_train[\"MaritalStatus\"] = X_train[\"MaritalStatus\"].cat.codes\n",
    "X_train[\"OverTime\"] = X_train[\"OverTime\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[X_test.select_dtypes(['category']).columns]\n",
    "X_test[\"BusinessTravel\"] = X_test[\"BusinessTravel\"].cat.codes\n",
    "X_test[\"Department\"] = X_test[\"Department\"].cat.codes\n",
    "X_test[\"EducationField\"] = X_test[\"EducationField\"].cat.codes\n",
    "X_test[\"Gender\"] = X_test[\"Gender\"].cat.codes\n",
    "X_test[\"JobRole\"] = X_test[\"JobRole\"].cat.codes\n",
    "X_test[\"MaritalStatus\"] = X_test[\"MaritalStatus\"].cat.codes\n",
    "X_test[\"OverTime\"] = X_test[\"OverTime\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         int64\n",
       "Age                        int64\n",
       "BusinessTravel              int8\n",
       "Department                  int8\n",
       "Education                  int64\n",
       "EducationField              int8\n",
       "EmployeeNumber             int64\n",
       "EnvironmentSatisfaction    int64\n",
       "Gender                      int8\n",
       "JobInvolvement             int64\n",
       "JobRole                     int8\n",
       "JobSatisfaction            int64\n",
       "MaritalStatus               int8\n",
       "MonthlyIncome              int64\n",
       "NumCompaniesWorked         int64\n",
       "OverTime                    int8\n",
       "PercentSalaryHike          int64\n",
       "PerformanceRating          int64\n",
       "StockOptionLevel           int64\n",
       "TotalWorkingYears          int64\n",
       "TrainingTimesLastYear      int64\n",
       "YearsAtCompany             int64\n",
       "YearsInCurrentRole         int64\n",
       "YearsSinceLastPromotion    int64\n",
       "YearsWithCurrManager       int64\n",
       "CommunicationSkill         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "66Pr1G_89jVI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1628, 26)\n",
      "(470, 26)\n",
      "(1628,)\n"
     ]
    }
   ],
   "source": [
    "#LET US PRINT THE SHAPES\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "#print(y_test.shape)\n",
    "\n",
    "#print('\\nExpected shapes')\n",
    "#print((1722, 25))\n",
    "#print((431, 25))\n",
    "#print((1722,))\n",
    "#print((431,))\n",
    "#print('\\nVerify if they are matching')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MTbjksBn9jVK"
   },
   "source": [
    "NOW <br>\n",
    "LET US APPLY LINEAR REGRESSION ON THE DATA, THIS TIME WE WILL IMPORT IT FROM SKLEARN <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qza5_BMn9jVK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Training R2 score is 0.23407473385401723\n",
      "0.1231796736141925\n",
      "0.23793907551150006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(\"\\n\")\\nprint(\"The correct values are :\")\\n\\n\\nprint(\\'Linear Regression Training R2 score is -1.4647261441743633\\')\\nprint(\\'Linear Regression Testing R2 score is -1.3922764470190696\\')\\nprint(\\'Linear Regression Training mean_square_error is 90997459.24038002\\')\\nprint(\\'Linear Regression Testing mean_square_error is 93998879.06677869\\')\\nprint(\\'Linear Regression Training mean_absolute_error is 6864.980505017769\\')\\nprint(\\'Linear Regression Testing mean_absolute_error is 6926.987292556893\\')\\n\\nprint(\"\\nPlease verify if you have got the same values\")'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "# INITIALIZE LINEAR REGRESSION WITH ALL DEFAULT PARAMETERS\n",
    "Linreg = LinearRegression()\n",
    "Linreg.fit(X_train,y_train)\n",
    "\n",
    "# FIND TEST ERROR AND TRAIN ERROR WITH THE METRICS IMPORTED ABOVE\n",
    "# NOTE THAT WE HAVE SQUARED BACK THE VALUES AS WE ARE PREDICTING PRICES NOT THEIR SQUARE ROOT \n",
    "print(\"Linear Regression Training R2 score is \" + str(r2_score(np.square(Linreg.predict(X_train)),np.square(y_train))))\n",
    "#print(\"Linear Regression Testing R2 score is \" + str(r2_score(np.square(Linreg.predict(X_test)),np.square(y_test))))\n",
    "\n",
    "# WRITE CODE FOR MEAN SQUARE ERROR AND MEAN\n",
    "\n",
    "# Start code\n",
    "#y_predict=Linreg.predict(X_train)\n",
    "MSE_training=mean_squared_error(np.square(y_train),np.square(Linreg.predict(X_train)))\n",
    "#MSE_testing=mean_squared_error(np.square(y_test),np.square(Linreg.predict(X_test)))\n",
    "\n",
    "MAE_training=mean_absolute_error(np.square(y_train),np.square(Linreg.predict(X_train)))\n",
    "#MAE_testing=mean_absolute_error(np.square(y_test),np.square(Linreg.predict(X_test)))\n",
    "\n",
    "print(MSE_training)\n",
    "#print(MSE_testing)\n",
    "print(MAE_training)\n",
    "#print(MAE_testing)\n",
    "# End code\n",
    "\n",
    "\"\"\"print(\"\\n\")\n",
    "print(\"The correct values are :\")\n",
    "\n",
    "\n",
    "print('Linear Regression Training R2 score is -1.4647261441743633')\n",
    "print('Linear Regression Testing R2 score is -1.3922764470190696')\n",
    "print('Linear Regression Training mean_square_error is 90997459.24038002')\n",
    "print('Linear Regression Testing mean_square_error is 93998879.06677869')\n",
    "print('Linear Regression Training mean_absolute_error is 6864.980505017769')\n",
    "print('Linear Regression Testing mean_absolute_error is 6926.987292556893')\n",
    "\n",
    "print(\"\\nPlease verify if you have got the same values\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "Linreg.predict(X_test)\n",
    "arr_Lin=np.array(Linreg.predict(X_test))\n",
    "np.savetxt('LinearRegressor.csv', [arr_Lin], delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z3W4-0--9jVN"
   },
   "source": [
    "<br>\n",
    "NOW LET US WRITE THE SKLEARN IMPLEMENTATION OF DECISION TREE IN REGRESSION <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f43pHl3y9jVO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Training R2 score is 1.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "\n",
    "# INITIALIZE THE DECISION TREE WITH criterion as mse, max depth as 7 and Random State as 1\n",
    "# USE THE FIT METHOD TO FIND THE R2_SCORE, MSE, MAE For training as well as testing data\n",
    "#DT_regressor = DecisionTreeRegressor(criterion='mse',max_depth=11,random_state=1)\n",
    "DT_regressor = DecisionTreeRegressor()\n",
    "DT_regressor.fit(X_train,y_train)\n",
    "print(\"Decision Tree Training R2 score is \" + str(r2_score(np.square(y_train),np.square(DT_regressor.predict(X_train)))))\n",
    "#print(\"Decision Tree Testing R2 score is \" + str(r2_score(np.square(y_test),np.square(DT_regressor.predict(X_test)))))\n",
    "\n",
    "# START COD\n",
    "MSE_training_DT=mean_squared_error(np.square(y_train),np.square(DT_regressor.predict(X_train)))\n",
    "#MSE_testing_DT=mean_squared_error(np.square(y_test),np.square(DT_regressor.predict(X_test)))\n",
    "\n",
    "MAE_training_DT=mean_absolute_error(np.square(y_train),np.square(DT_regressor.predict(X_train)))\n",
    "#MAE_testing_DT=mean_absolute_error(np.square(y_test),np.square(DT_regressor.predict(X_test)))\n",
    "\n",
    "print(MSE_training_DT)\n",
    "#print(MSE_testing_DT)\n",
    "print(MAE_training_DT)\n",
    "#print(MAE_testing_DT)\n",
    "\n",
    "# END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_regressor.predict(X_test)\n",
    "arr_DT=np.array(DT_regressor.predict(X_test))\n",
    "np.savetxt('DTRegressor.csv', [arr_DT], delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TvQ6cQkC9jVQ"
   },
   "source": [
    "<br>\n",
    "NOW LET US WRITE THE SKLEARN IMPLEMENTATION OF SVM IN REGRESSION <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTlrmqiG9jVQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Training R2 score is 0.15556035046108263\n",
      "0.13410245749748415\n",
      "0.2443137312472775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "# INITIALIZE THE SVM WITH kernel as 'poly', maximum number of iterations as 3000, degree as 2, C(regularization parameter) as 0.1 \n",
    "# FIT THE DATA using FIT METHOD\n",
    "# Calculate the R2_score, mse, mae for training data as well as testing data.\n",
    "\n",
    "# START CODE\n",
    "#clf = SVR(kernel='poly',max_iter=3000,degree=2,C=0.1)\n",
    "clf_SVR = SVR()\n",
    "clf_SVR.fit(X_train,y_train)\n",
    "print(\"SVM Training R2 score is \" + str(r2_score(np.square(clf.predict(X_train)),np.square(y_train))))\n",
    "#print(\"SVM Testing R2 score is \" + str(r2_score(np.square(clf.predict(X_test)),np.square(y_test))))\n",
    "\n",
    "MSE_training_SVM=mean_squared_error(np.square(y_train),np.square(clf.predict(X_train)))\n",
    "#MSE_testing_SVM=mean_squared_error(np.square(y_test),np.square(clf.predict(X_test)))\n",
    "\n",
    "MAE_training_SVM=mean_absolute_error(np.square(y_train),np.square(clf.predict(X_train)))\n",
    "#MAE_testing_SVM=mean_absolute_error(np.square(y_test),np.square(clf.predict(X_test)))\n",
    "\n",
    "print(MSE_training_SVM)\n",
    "#print(MSE_testing_SVM)\n",
    "print(MAE_training_SVM)\n",
    "#print(MAE_testing_SVM)\n",
    "\n",
    "# END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVR.predict(X_test)\n",
    "arr_SVR=np.array(clf_SVR.predict(X_test))\n",
    "np.savetxt('SVRRegressor.csv', [arr_SVR], delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GByCRcmJ9jVT"
   },
   "source": [
    "YOU MIGHT SEE WORSE VALUES WHEN COMPARED TO LINEAR REGRESSION OR DECISION TREE AS THE DATA IS UNSCALED AND SVM REQUIRES MUCH MORE PREPROCESSING AND TUNING...BUT WE WON'T DO THAT HERE AS OUR AIM WAS JUST TO IMPLEMENT THE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BEE9QB4O9jVT"
   },
   "source": [
    "<br>\n",
    "NOW LET US WRITE THE SKLEARN IMPLEMENTATION OF Random Forest IN REGRESSION <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uqrGh5AR9jVU"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# INITIALIZE THE Random Forest Regressor WITH no: of trees as 200, max_depth as 9, n_jobs as -1(read documentation for more details) and random state as 1 \n",
    "\n",
    "# FIT THE DATA using FIT METHOD\n",
    "# Calculate the R2_score, mse, mae for training data as well as testing data.\n",
    "\n",
    "# START CODE\n",
    "#regr = RandomForestRegressor(n_estimators=200,max_depth=9,n_jobs=-1,random_state=1)\n",
    "#regr = RandomForestRegressor() -30-05-19 (1)\n",
    "#regr = RandomForestRegressor(n_estimators=200,max_depth=9,n_jobs=-1,random_state=1) -30-05-19 (2)\n",
    "#regr = RandomForestRegressor(n_estimators=300,n_jobs=-1,random_state=1)-30-05-19 (3)\n",
    "regr = RandomForestRegressor(n_estimators=50,criterion= 'mae')\n",
    "regr.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print(\"Random Forest Training R2 score is \" + str(r2_score(np.square(regr.predict(X_train)),np.square(y_train))))\n",
    "#print(\"Random Forest Testing R2 score is \" + str(r2_score(np.square(regr.predict(X_test)),np.square(y_test))))\n",
    "\n",
    "MSE_training_RF=mean_squared_error(np.square(y_train),np.square(regr.predict(X_train)))\n",
    "#MSE_testing_RF=mean_squared_error(np.square(y_test),np.square(regr.predict(X_test)))\n",
    "\n",
    "MAE_training_RF=mean_absolute_error(np.square(y_train),np.square(regr.predict(X_train)))\n",
    "#MAE_testing_RF=mean_absolute_error(np.square(y_test),np.square(regr.predict(X_test)))\n",
    "\n",
    "print(MSE_training_RF)\n",
    "#print(MSE_testing_RF)\n",
    "print(MAE_training_RF)\n",
    "#print(MAE_testing_RF)\n",
    "\n",
    "# END CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=np.array(regr.predict(X_test))\n",
    "np.savetxt(r'C:\\Users\\inspire\\Desktop\\Submissions\\RandomForestRegressor_3.csv', [arr], delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sUEvPws29jVW"
   },
   "source": [
    "NOW FOR CLASSIFICATION MODELS WE NEED TO CONVERT THE TARGET VARIABLE INTO DIFFERENT CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SxdlNAd49jVa"
   },
   "source": [
    "WE WILL DO BINARY CLASSIFICATION AND DIVIDE THE DATA EQUALLY(ALMOST) INTO 1's AND 0's <br>\n",
    "WE HAVE CHOSEN THRESHOLD AT price = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWKZZWms9jVh"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mWkYGoJZ9jVj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INITIALIZE Logistic Regression BY TAKING solver as 'lbfgs', max_iter as 2000, C as 0.5 and penalty as 'l2' and random_state as 1 \n",
    "# FIT SVM ON TRAINING DATA\n",
    "# WRITE CODE HERE AND FIND THE TPR, FPR, SENSTIVITY, SPECIFICITY, ACCURACY FOR LOGISTIC REGRESSION\n",
    "# USE THE IMPORTED CONFUSION MATRIX\n",
    "clf = LogisticRegression(solver='lbfgs',max_iter=2000,C=0.5,penalty='l2',random_state=1)\n",
    "clf.fit(X_train,y_train)\n",
    "# START CODE\n",
    "#Training\n",
    "tn_training_LR, fp_training_LR, fn_training_LR, tp_training_LR = confusion_matrix(y_train,clf.predict(X_train)).ravel()\n",
    "TPR_training_LR=tp_training_LR/(fn_training_LR+tp_training_LR)\n",
    "FPR_training_LR=fp_training_LR/(tn_training_LR+fp_training_LR)\n",
    "TNR_training_LR=tn_training_LR/(tn_training_LR+fp_training_LR)\n",
    "Accuracy_training_LR=(tp_training_LR+tn_training_LR)/(tn_training_LR+fp_training_LR+fn_training_LR+tp_training_LR)\n",
    "Sensitivity_training_LR=TPR_training_LR\n",
    "Specificity_training_LR=tn_training_LR/(fp_training_LR+tn_training_LR)\n",
    "\n",
    "#Testing\n",
    "'''tn_testing_LR, fp_testing_LR, fn_testing_LR, tp_testing_LR = confusion_matrix(y_test,clf.predict(X_test)).ravel()\n",
    "TPR_testing_LR=tp_testing_LR/(fn_testing_LR+tp_testing_LR)\n",
    "FPR_testing_LR=fp_testing_LR/(tn_testing_LR+fp_testing_LR)\n",
    "TNR_testing_LR=tn_testing_LR/(tn_testing_LR+fp_testing_LR)\n",
    "Accuracy_testing_LR=(tp_testing_LR+tn_testing_LR)/(tn_testing_LR+fp_testing_LR+fn_testing_LR+tp_testing_LR)\n",
    "Sensitivity_testing_LR=TPR_testing_LR\n",
    "Specificity_testing_LR=tn_testing_LR/(fp_testing_LR+tn_testing_LR)\n",
    "\n",
    "# END CODE\n",
    "#TPR_training_LR\n",
    "#TNR_testing_LR'''\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wGv7G_Q29jVl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INITIALIZE SVM BY TAKING kernal as 'rbf', max_iter as 1000 and random_state as 1\n",
    "# FIT SVM ON TRAINING DATA\n",
    "# WRITE CODE HERE AND FIND THE TPR, FPR, SENSTIVITY, SPECIFICITY, ACCURACY FOR LOGISTIC REGRESSION\n",
    "# USE THE IMPORTED CONFUSION MATRIX\n",
    "clf = SVC(kernel='rbf',max_iter=1000,random_state=1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# START CODE\n",
    "#Training\n",
    "tn_training_SVM, fp_training_SVM, fn_training_SVM, tp_training_SVM = confusion_matrix(y_train,clf.predict(X_train)).ravel()\n",
    "TPR_training_SVM=tp_training_SVM/(fn_training_SVM+tp_training_SVM)\n",
    "FPR_training_SVM=fp_training_SVM/(tn_training_SVM+fp_training_SVM)\n",
    "TNR_training_SVM=tn_training_SVM/(tn_training_SVM+fp_training_SVM)\n",
    "Accuracy_training_SVM=(tp_training_SVM+tn_training_SVM)/(tn_training_SVM+fp_training_SVM+fn_training_SVM+tp_training_SVM)\n",
    "Sensitivity_training_SVM=TPR_training_SVM\n",
    "Specificity_training_SVM=tn_training_SVM/(fp_training_SVM+tn_training_SVM)\n",
    "\n",
    "#Testing\n",
    "'''tn_testing_SVM, fp_testing_SVM, fn_testing_SVM, tp_testing_SVM = confusion_matrix(y_test,clf.predict(X_test)).ravel()\n",
    "TPR_testing_SVM=tp_testing_SVM/(fn_testing_SVM+tp_testing_SVM)\n",
    "FPR_testing_SVM=fp_testing_SVM/(tn_testing_SVM+fp_testing_SVM)\n",
    "TNR_testing_SVM=tn_testing_SVM/(tn_testing_SVM+fp_testing_SVM)\n",
    "Accuracy_testing_SVM=(tp_testing_SVM+tn_testing_SVM)/(tn_testing_SVM+fp_testing_SVM+fn_testing_SVM+tp_testing_SVM)\n",
    "Sensitivity_testing_SVM=TPR_testing_SVM\n",
    "Specificity_testing_SVM=tn_testing_SVM/(fp_testing_SVM+tn_testing_SVM)\n",
    "\n",
    "# END CODE\n",
    "#Sensitivity_training_SVM\n",
    "Accuracy_testing_SVM'''\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8OSZT7q9jVn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INITIALIZE DECISION TREE CLASSIFIER BY TAKING criterion as 'gini' , max_depth as 3, and random_state as 1\n",
    "# FIT LOGISTIC REGRESSION ON TRAINING DATA\n",
    "# WRITE CODE HERE AND FIND THE TPR, FPR, SENSTIVITY, SPECIFICITY, ACCURACY FOR LOGISTIC REGRESSION\n",
    "# USE THE IMPORTED CONFUSION MATRIX\n",
    "clf = DecisionTreeClassifier(criterion='gini',max_depth=3,random_state=1)\n",
    "clf.fit(X_train,y_train)\n",
    "# START CODE\n",
    "#Training\n",
    "tn_training_DT, fp_training_DT, fn_training_DT, tp_training_DT = confusion_matrix(y_train,clf.predict(X_train)).ravel()\n",
    "TPR_training_DT=tp_training_DT/(fn_training_DT+tp_training_DT)\n",
    "FPR_training_DT=fp_training_DT/(tn_training_DT+fp_training_DT)\n",
    "TNR_training_DT=tn_training_DT/(tn_training_DT+fp_training_DT)\n",
    "Accuracy_training_DT=(tp_training_DT+tn_training_DT)/(tn_training_DT+fp_training_DT+fn_training_DT+tp_training_DT)\n",
    "Sensitivity_training_DT=TPR_training_DT\n",
    "Specificity_training_DT=tn_training_DT/(fp_training_DT+tn_training_DT)\n",
    "\n",
    "#Testing\n",
    "'''tn_testing_DT, fp_testing_DT, fn_testing_DT, tp_testing_DT = confusion_matrix(y_test,clf.predict(X_test)).ravel()\n",
    "TPR_testing_DT=tp_testing_DT/(fn_testing_DT+tp_testing_DT)\n",
    "FPR_testing_DT=fp_testing_DT/(tn_testing_DT+fp_testing_DT)\n",
    "TNR_testing_DT=tn_testing_DT/(tn_testing_DT+fp_testing_DT)\n",
    "Accuracy_testing_DT=(tp_testing_DT+tn_testing_DT)/(tn_testing_DT+fp_testing_DT+fn_testing_DT+tp_testing_DT)\n",
    "Sensitivity_testing_DT=TPR_testing_DT\n",
    "Specificity_testing_DT=tn_testing_DT/(fp_testing_DT+tn_testing_DT)\n",
    "\n",
    "# END \n",
    "#Specificity_training_DT\n",
    "Accuracy_testing_DT'''\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=np.array(clf.predict(X_test))\n",
    "np.savetxt('DTClassifier.csv', [arr], delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HZRx_Rez9jVq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INITIALIZE RANDOM FOREST CLASSIFIER BY TAKING no:of trees as 100 , max_depth as 3,criterion as 'gini' and random_state as 1 \n",
    "# FIT RANDOM FOREST ON TRAINING DATA\n",
    "# WRITE CODE HERE AND FIND THE TPR, FPR, SENSTIVITY, SPECIFICITY, ACCURACY FOR LOGISTIC REGRESSION\n",
    "# USE THE IMPORTED CONFUSION MATRIX\n",
    "clf = RandomForestClassifier(n_estimators=100,max_depth=3,criterion='gini',random_state=1)\n",
    "clf.fit(X_train,y_train)\n",
    "# START CODE\n",
    "#Training\n",
    "tn_training_RF, fp_training_RF, fn_training_RF, tp_training_RF = confusion_matrix(y_train,clf.predict(X_train)).ravel()\n",
    "TPR_training_RF=tp_training_RF/(fn_training_RF+tp_training_RF)\n",
    "FPR_training_RF=fp_training_RF/(tn_training_RF+fp_training_RF)\n",
    "TNR_training_RF=tn_training_RF/(tn_training_RF+fp_training_RF)\n",
    "Accuracy_training_RF=(tp_training_RF+tn_training_RF)/(tn_training_RF+fp_training_RF+fn_training_RF+tp_training_RF)\n",
    "Sensitivity_training_RF=TPR_training_RF\n",
    "Specificity_training_RF=tn_training_RF/(fp_training_RF+tn_training_RF)\n",
    "\n",
    "#Testing\n",
    "'''tn_testing_RF, fp_testing_RF, fn_testing_RF, tp_testing_RF = confusion_matrix(y_test,clf.predict(X_test)).ravel()\n",
    "TPR_testing_RF=tp_testing_RF/(fn_testing_RF+tp_testing_RF)\n",
    "FPR_testing_RF=fp_testing_RF/(tn_testing_RF+fp_testing_RF)\n",
    "TNR_testing_RF=tn_testing_RF/(tn_testing_RF+fp_testing_RF)\n",
    "Accuracy_testing_RF=(tp_testing_RF+tn_testing_RF)/(tn_testing_RF+fp_testing_RF+fn_testing_RF+tp_testing_RF)\n",
    "Sensitivity_testing_RF=TPR_testing_RF\n",
    "Specificity_testing_RF=tn_testing_RF/(fp_testing_RF+tn_testing_RF)\n",
    "\n",
    "# END CODE\n",
    "#TPR_training_RF\n",
    "Accuracy_testing_RF'''\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WEEK4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
